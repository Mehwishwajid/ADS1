# -*- coding: utf-8 -*-
"""cluster_fitt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jv1iSfJNNrXRGbOiZtDAQKvHlOACmr_w
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn.cluster as cluster
import sklearn.metrics as skmet
from sklearn.preprocessing import MinMaxScaler
import scipy.optimize as opt

def read_data(file):
    """
    The function accepts a file and reads it into a pandas DataFrame and
    cleans it and transposes it. It returns the cleaned original and
    transposed DataFrame.

    Parameters
    ----------
    file : string
        The file name to be read into DataFrame.

    Returns
    -------
    df_clean : pandas DataFrame
        The cleaned version of the ingested DataFrame.
    df_t : pandas DataFrame
        The transposed version of the cleaned DataFrame.

    """

    # reads in an excel file
    if ".xlsx" in file:
        df = pd.read_excel(file, index_col=0)
    # reads in a csv file
    elif ".csv" in file:
        df = pd.read_csv(file, index_col=0)
    else:
        print("invalid filetype")
    # cleans the DataFrame
    df_clean = df.dropna(axis=1, how="all").dropna()
    # transposes the cleaned DataFrame
    df_t = df_clean.transpose()

    return df_clean, df_t

def kmeans_cluster(nclusters, df_cluster):
    """
    The function produces cluster centers and labels through kmeans
    clustering of given number of clusters and returns the cluster
    centers and the cluster labels.

    Parameters
    ----------
    nclusters : int
        The number of clusters.
    df_cluster : pandas DataFrame
        The dataframe in which clustering is performed.

    Returns
    -------
    labels : array
        The labels of the clusters.
    cen : array
        The coordinates of the cluster centres.

    """
    kmeans = cluster.KMeans(n_clusters=nclusters)
    # df_cluster is the dataframe in which clustering is performed
    kmeans.fit(df_cluster)
    labels = kmeans.labels_
    cen = kmeans.cluster_centers_

    return labels, cen

def poly(x, a, b, c):
    """
    The function which produces a polynomial curve for fitting the data.

    Parameters
    ----------
    x : int or float
        The variable of the polynomial.
    a : int or float
        The constant of the polynomial.
    b : int or float
        The coefficient of x.
    c : int or float
        The coefficient of x**2.

    Returns
    -------
    f : array
        The polynomial curve.

    """

    x = x - 2003
    f = a + b*x + c*x**2

    return f

# the csv files are read into dataframes
_, co2_df = read_data("co2_emissions.csv")
print(co2_df)

_, gdp_per_capita_df = read_data("gdp_per_capita.csv")
print(gdp_per_capita_df)

# Specific columns are extracted
co2_china = co2_df.loc[:, "China"].copy()
print(co2_china)

gdp_per_capita_china = gdp_per_capita_df.loc["1990":"2019", "China"].copy()
print(gdp_per_capita_china)

# The extracted columns are merged into a dataframe
df_china = pd.merge(co2_china, gdp_per_capita_china, on=co2_china.index,
                    how="outer")
df_china = df_china.rename(columns={'key_0': "Year",
                                    'China_x': "co2_emissions",
                                    'China_y': "gdp_per_capita"})
df_china = df_china.set_index("Year")
print(df_china)

# The dataframe for clustering is created
df_cluster = df_china[["co2_emissions", "gdp_per_capita"]].copy()

# Instead of using the scaler function from cluster_tools module, you can use MinMaxScaler from sklearn
scaler = MinMaxScaler()
df_cluster_scaled = scaler.fit_transform(df_cluster)

# The number of clusters and respective silhouette scores are printed
print("n   score")
for ncluster in range(2, 10):
    labels, centroids = kmeans_cluster(ncluster, df_cluster_scaled)
    silhouette_score = skmet.silhouette_score(df_cluster_scaled, labels)
    print(ncluster, silhouette_score)

# The cluster centers and labels are calculated using the function
labels, center = kmeans_cluster(5, df_cluster_scaled)
xcen = center[:, 0]
ycen = center[:, 1]

# The clustering is plotted
plt.figure()
cm = plt.cm.get_cmap('Set1')
plt.scatter(df_cluster['gdp_per_capita'], df_cluster["co2_emissions"], s=10,
            c=labels, marker='o', cmap=cm)
plt.scatter(xcen, ycen, s=20, c="k", marker="d")
plt.title("CO2 emission vs GDP per capita of China", fontsize=20)
plt.xlabel("GDP per capita", fontsize=18)
plt.ylabel("CO2 emissions", fontsize=18)
plt.show()

# The dataframe is prepared for fitting
df_china = df_china.reset_index()
df_china["gdp_per_capita"] = pd.to_numeric(df_china["gdp_per_capita"])
df_china["Year"] = pd.to_numeric(df_china["Year"])

# The fitting of the GDP per capita plot
# Calculates the parameters and covariance
param, covar = opt.curve_fit(poly, df_china["Year"],
                             df_china["gdp_per_capita"])
# Calculates the standard deviation
sigma = np.sqrt(np.diag(covar))
year = np.arange(1990, 2030)
# Calculates the fitting curve
forecast = poly(year, *param)

# Plots the graph with fitting and confidence range
plt.figure()
plt.plot(df_china["Year"], df_china["gdp_per_capita"], label="GDP", c='blue')
plt.plot(year, forecast, label="forecast", c='red')
plt.xlabel("Year", fontsize=16)
plt.ylabel("GDP per capita", fontsize=14)
plt.title("GDP per capita forecast of China", fontsize=18)
plt.legend()
plt.show()

# The fitting of CO2 Emissions plot
# Calculates the parameters and covariance
param, covar = opt.curve_fit(poly, df_china["Year"], df_china["co2_emissions"])
# Calculates the standard deviation
sigma = np.sqrt(np.diag(covar))
# Calculates the fitting curve
forecast = poly(year, *param)

# Plots the graph with fitting and confidence range
plt.figure()
plt.plot(df_china["Year"], df_china["co2_emissions"], label="CO2 emissions",
         c='green')
plt.plot(year, forecast, label="forecast", c="red")
plt.xlabel("Year", fontsize=16)
plt.ylabel("CO2 Emissions (metric tons per capita)", fontsize=12)
plt.title("CO2 Emissions Forecast of China", fontsize=18)
plt.legend()
plt.show()